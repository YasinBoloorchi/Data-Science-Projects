{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Notebook\n",
    "<br> \n",
    "Yazdan Asadi <br>\n",
    "9517023104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Want a Neural Net with input layer = 3 <br>\n",
    "Output Layer = 1 <br>\n",
    "hidden Layer = 4 <br>\n",
    "and then train it with 5 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_sigmoid(x):\n",
    "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "      fx = sigmoid(x)\n",
    "      return fx * (1 - fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    '''A neural network with:\n",
    "    - 3 inputs\n",
    "    - a hidden layer with 4 neurons (h1, h2,h3,h4)\n",
    "    - an output layer with 1 neuron (o1)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # Weights\n",
    "        self.w1 = 0.1\n",
    "        self.w2 = 0.1\n",
    "        self.w3 = 0.1\n",
    "        self.w4 = 0.1\n",
    "        self.w5 = 0.1\n",
    "        self.w6 = 0.1\n",
    "        self.w7 = 0.1\n",
    "        self.w8 = 0.1\n",
    "        self.w9 = 0.1\n",
    "        self.w10= 0.1\n",
    "        self.w11= 0.1\n",
    "        self.w12= 0.1\n",
    "        self.w13= np.random.normal()\n",
    "        self.w14= np.random.normal()\n",
    "        self.w15= np.random.normal()\n",
    "        self.w16= np.random.normal()\n",
    "        # Biases\n",
    "        self.b1 = np.random.normal()\n",
    "        self.b2 = np.random.normal()\n",
    "        self.b3 = np.random.normal()\n",
    "        self.b4 = np.random.normal()\n",
    "        self.b5 = np.random.normal()\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        # x is a numpy array with 3 elements.\n",
    "        h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.w3 * x[2] + self.b1)\n",
    "        h2 = sigmoid(self.w4 * x[0] + self.w5 * x[1] + self.w6 * x[2] + self.b2)\n",
    "        h3 = sigmoid(self.w7 * x[0] + self.w8 * x[1] + self.w9 * x[2] + self.b3)\n",
    "        h4 = sigmoid(self.w10 * x[0] + self.w11 * x[1] + self.w12 * x[2] + self.b4)\n",
    "        o1 = sigmoid(self.w13 * h1 + self.w14 * h2 + self.w15 * h3 + self.w16 * h4 + self.b5)\n",
    "        print(o1)\n",
    "        if o1 >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    def train(self, data, all_y_trues):\n",
    "            '''\n",
    "            - data is a (n x int ) numpy array, n = # of samples in the dataset.\n",
    "            - all_y_trues is a numpy array with n elements.\n",
    "            Elements in all_y_trues correspond to those in data.\n",
    "            '''\n",
    "            learn_rate = 0.1\n",
    "            epochs = 5 #number of epochs to learn in nn\n",
    "            for epoch in range(epochs):\n",
    "                for x, y_true in zip(data, all_y_trues):\n",
    "                    sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.w3 * x[2] + self.b1\n",
    "                    h1 = sigmoid(sum_h1)\n",
    "                    sum_h2 = self.w4 * x[0] + self.w5 * x[1] + self.w6 * x[2] + self.b2\n",
    "                    h2 = sigmoid(sum_h2)\n",
    "                    sum_h3 = self.w7 * x[0] + self.w8 * x[1] + self.w9 * x[2] + self.b3\n",
    "                    h3 = sigmoid(sum_h3)\n",
    "                    sum_h4 = self.w10 * x[0] + self.w11 * x[1] + self.w12 * x[2] + self.b4\n",
    "                    h4 = sigmoid(sum_h4)\n",
    "                \n",
    "                    sum_o1 = self.w13 * h1 + self.w14 * h2 + self.w15 * h3 + self.w16 * h4 + self.b5\n",
    "                    o1 = sigmoid(sum_o1)\n",
    "                    y_pred = o1\n",
    "                    # --- Calculate partial derivatives.\n",
    "                    # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n",
    "                    d_L_d_ypred = -2 * (y_true - y_pred)\n",
    "    \n",
    "                    # Neuron o1\n",
    "                    d_ypred_d_w13 = h1 * deriv_sigmoid(sum_o1)\n",
    "                    d_ypred_d_w14 = h2 * deriv_sigmoid(sum_o1)\n",
    "                    d_ypred_d_w15 = h2 * deriv_sigmoid(sum_o1)\n",
    "                    d_ypred_d_w16 = h2 * deriv_sigmoid(sum_o1)\n",
    "                    d_ypred_d_b5 = deriv_sigmoid(sum_o1)\n",
    "\n",
    "                    d_ypred_d_h1 = self.w13 * deriv_sigmoid(sum_o1)\n",
    "                    d_ypred_d_h2 = self.w14 * deriv_sigmoid(sum_o1)\n",
    "                    d_ypred_d_h3 = self.w15 * deriv_sigmoid(sum_o1)\n",
    "                    d_ypred_d_h4 = self.w16 * deriv_sigmoid(sum_o1)\n",
    "                \n",
    "                    # Neuron h1\n",
    "                    d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
    "                    d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
    "                    d_h1_d_w3 = x[2] * deriv_sigmoid(sum_h1)\n",
    "                    d_h1_d_b1 = deriv_sigmoid(sum_h1)\n",
    "\n",
    "                    # Neuron h2\n",
    "                    d_h2_d_w4 = x[0] * deriv_sigmoid(sum_h2)\n",
    "                    d_h2_d_w5 = x[1] * deriv_sigmoid(sum_h2)\n",
    "                    d_h2_d_w6 = x[2] * deriv_sigmoid(sum_h2)\n",
    "                    d_h2_d_b2 = deriv_sigmoid(sum_h2)\n",
    "                \n",
    "                    # Neuron h3\n",
    "                    d_h3_d_w7 = x[0] * deriv_sigmoid(sum_h3)\n",
    "                    d_h3_d_w8 = x[1] * deriv_sigmoid(sum_h3)\n",
    "                    d_h3_d_w9 = x[2] * deriv_sigmoid(sum_h3)\n",
    "                    d_h3_d_b3 = deriv_sigmoid(sum_h2)\n",
    "                \n",
    "                    # Neuron h4\n",
    "                    d_h4_d_w10 = x[0] * deriv_sigmoid(sum_h4)\n",
    "                    d_h4_d_w11 = x[1] * deriv_sigmoid(sum_h4)\n",
    "                    d_h4_d_w12 = x[2] * deriv_sigmoid(sum_h4)\n",
    "                    d_h4_d_b4 = deriv_sigmoid(sum_h4)\n",
    "                \n",
    "                \n",
    "                    # --- Update weights and biases\n",
    "                    \n",
    "                \n",
    "                    # Neuron h1\n",
    "                    self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "                    self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
    "                    self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w3\n",
    "                    self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
    "\n",
    "                \n",
    "                    # Neuron h2\n",
    "                    self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
    "                    self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w5\n",
    "                    self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w6\n",
    "                    self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "                \n",
    "                    # Neuron h3\n",
    "                    self.w7 -= learn_rate * d_L_d_ypred * d_ypred_d_h3 * d_h3_d_w7\n",
    "                    self.w8 -= learn_rate * d_L_d_ypred * d_ypred_d_h3 * d_h3_d_w8\n",
    "                    self.w9 -= learn_rate * d_L_d_ypred * d_ypred_d_h3 * d_h3_d_w9\n",
    "                    self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_h3 * d_h3_d_b3\n",
    "                \n",
    "                    # Neuron h4\n",
    "                    self.w10 -= learn_rate * d_L_d_ypred * d_ypred_d_h4 * d_h4_d_w10\n",
    "                    self.w11 -= learn_rate * d_L_d_ypred * d_ypred_d_h4 * d_h4_d_w11\n",
    "                    self.w12 -= learn_rate * d_L_d_ypred * d_ypred_d_h4 * d_h4_d_w12\n",
    "                    self.b4  -= learn_rate * d_L_d_ypred * d_ypred_d_h4 * d_h4_d_b4\n",
    "                \n",
    "                    # Neuron o1\n",
    "                \n",
    "                    self.w13 -= learn_rate * d_L_d_ypred * d_ypred_d_w13\n",
    "                    self.w14 -= learn_rate * d_L_d_ypred * d_ypred_d_w14\n",
    "                    self.w15 -= learn_rate * d_L_d_ypred * d_ypred_d_w15\n",
    "                    self.b5  -= learn_rate * d_L_d_ypred * d_ypred_d_b5\n",
    "                \n",
    "                \n",
    "                # --- Calculate total loss at the end of each epoch\n",
    "            if epoch % 10 == 0:\n",
    "                y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
    "                loss = mse_loss(all_y_trues, y_preds)\n",
    "                print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High == -20\n",
    "# Low == 20\n",
    "# Medium == 0 \n",
    "# Release == 1\n",
    "# Wait == 0\n",
    "data = np.array([\n",
    "      [-20, -20,   -20],   # 1\n",
    "      [0,   -20,    20],   # 2\n",
    "      [0,   -20,    20],   # 3\n",
    "      [-20,   0,     20],  # 4\n",
    "      [-20,  20 ,  -20],    # 5\n",
    "      [20,   20 ,   20],    # 6\n",
    "      [-20, -20 ,   20],    # 7\n",
    "      [20,   20 ,  -20],    # 8\n",
    "      [0,     0 ,  -20],    # 9\n",
    "      [0,   -20 ,  -20]    #10\n",
    "    ])\n",
    "all_y_trues = np.array([\n",
    "  1, # 1\n",
    "  1, # 2\n",
    "  0, # 3\n",
    "  0, # 4\n",
    "  0, # 5\n",
    "  0, # 6\n",
    "  0, # 7\n",
    "  1, # 8\n",
    "  0, # 9\n",
    "  1  # 10\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our neural network\n",
    "network = NeuralNetwork()\n",
    "network.train(data, all_y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2821585504345985\n",
      "New Record: 1.000\n"
     ]
    }
   ],
   "source": [
    "New_RECORD = np.array([-20, 20, -20]) \n",
    "\n",
    "print(\"New Record: %.3f\" % network.feedforward(New_RECORD)) # 0.951 - F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
